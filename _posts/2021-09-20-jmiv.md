---
title: JMIV - Paper Submission
categories: [Research, LRDE]
tags: [RDI, LRDE, JMIV]
pin: true
---

```
Deep Learning, Morphological Layer, CNN, Grayscale Morphology,
Research Paper, JMIV
```

<br /><br />

<center>
<h1>
Learning Grayscale Mathematical Morphology with SmoothMorphological Layers
</h1>
</center>

<br /><br />

After 6 months of working on the integration of mathematical morphology in a
neural network, I was able with the help of my supervisors to make a submission
to the Journal of Mathematical Imaging and Vision ([JMIV](https://springer.com/journal/10851)).

This article has been accepted and published in May 2022 ([Spinger Nature
link](https://link.springer.com/article/10.1007/s10851-022-01091-1?error=cookies_not_supported&code=1a3cd712-4a95-43eb-87c6-5e20380959b0)). The
publisher also made it available on [Research
Gate](https://www.researchgate.net/publication/360606987_Learning_Grayscale_Mathematical_Morphology_with_Smooth_Morphological_Layers),
with a full access for readers with institutional subscriptions.

I have posted the abstract and the pictures are below.

<br /><br />

## Abstract

The integration of mathematical morphology operations within convolutional
neural network architectures has received anincreasing attention lately.
However, replacing standard convolution layers by morphological layers
performing erosions ordilations is particularly challenging because the min and
max operations are not differentiable. P-convolution layers wereproposed as a
possible solution to this issue since they can act as smooth differentiable
approximation of min and maxoperations, yielding pseudo-dilation or
pseudo-erosion layers. In a recent work, we proposed two novel morphological
layersbased on the same principle as the p-convolution, while circumventing its
principal drawbacks, and showcased their capacityto efficiently learn grayscale
morphological operators while raising several edge cases. In this work, we
complete thoseprevious results by thoroughly analyzing the behavior of the
proposed layers and by investigating and settling the reportededge cases. We
also demonstrate the compatibility of one of the proposed morphological layers
with binary morphological frameworks. 

<br /><br />

## Article Figures

<a href="https://www.researchgate.net/figure/Top-illustration-of-the-dilation-of-the-pixel-13-with-red-borders-with-a-cross-shaped_fig1_360606987">
    <img src="https://www.researchgate.net/publication/360606987/figure/fig1/AS:1155814379261952@1652579030473/Top-illustration-of-the-dilation-of-the-pixel-13-with-red-borders-with-a-cross-shaped.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Top: illustration of the dilation of the pixel 13 (with red borders) with a
cross-shaped binary structuring element. Bottom: illustration of the dilation
of the same pixel 13 with a grayscale structuring element (Color figure
online)
</i>
</div><br /><br />


<a
href="https://www.researchgate.net/figure/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle_fig2_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig2/AS:1155814379270149@1652579030489/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Top row: input image from the MNIST database and non-flat structuring element
<span class="math inline"><em>w</em></span>. Middle row: <span class="math
inline">ℒMorph</span> pseudo-dilation for <span class="math
inline"><em>p</em> ∈ {0, 10, 20, 30}</span>, and target dilation <span
class="math inline"><em>f</em> ⊕ <em>w</em></span>. Bottom row: <span
class="math inline">ℒMorph</span> pseudo-erosion for <span class="math
inline"><em>p</em> ∈ {0,  − 10,  − 20,  − 30}</span> and target erosion <span
class="math inline"><em>f</em> ⊖ <em>w</em></span>. Note that for the erosion,
    <span class="math inline"> − <em>w</em></span> is used in <span class="math
    inline">ℒMorph</span> instead of <span class="math inline"><em>w</em></span>
    to approximate the the target <span class="math
    inline"><em>f</em> ⊖ <em>w</em></span>.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle_fig3_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig3/AS:1155814379257856@1652579030542/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Top row: input image from the MNIST database and non-flat structuring element
<span class="math inline"><em>w</em></span>. Middle row: <span class="math
inline">𝒮Morph</span> pseudo-dilation for <span class="math
inline"><em>α</em> ∈ {0, 5, 20, 30}</span>, and target dilation <span
class="math inline"><em>f</em> ⊕ <em>w</em></span>. Bottom row: <span
class="math inline">𝒮Morph</span> pseudo-erosion for <span class="math
inline"><em>α</em> ∈ {0,  − 5,  − 20,  − 30}</span> and target erosion <span
class="math inline"><em>f</em> ⊖ <em>w</em></span>. Note that for the erosion,
    <span class="math inline"> − <em>w</em></span> is used in <span class="math
    inline">𝒮Morph</span> instead of <span class="math inline"><em>w</em></span>
    to approximate the the target <span class="math
    inline"><em>f</em> ⊖ <em>w</em></span>.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig4_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig4/AS:1155814379266053@1652579030564/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
7<span class="math inline">×</span>7 target grayscale structuring elements.
All values range between <span class="math inline">0</span> (deep blue) and
<span class="math inline">1</span> (yellow).

</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Network-architecture-used-for-the-erosion-dilation-scenarios-Blue-blocks-are-trainable_fig5_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig5/AS:1155814379274242@1652579030597/Network-architecture-used-for-the-erosion-dilation-scenarios-Blue-blocks-are-trainable.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Network architecture used for the erosion/dilation scenarios. Blue blocks are
trainable units. A scenario is defined as the choice of <span class="math
inline">⊕</span> or <span class="math inline">⊖</span> and one of the 6 target
structuring elements in the upper path, and the choice of one layer among <span
class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>,
    <span class="math inline">ℒMorph</span> and <span class="math
    inline">𝒮Morph</span> in the lower path.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal_fig6_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig6/AS:1155814379261954@1652579030617/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filter <span class="math inline"><em>w</em></span>, corresponding
parameter <span class="math inline"><em>p</em>/<em>α</em></span>, RMSE between
the learned filter and the target structuring element, MSE training loss at
convergence and number of training epochs for <span class="math
inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span
class="math inline">ℒMorph</span> and <span class="math inline">𝒮Morph</span>
layers on an erosion <span class="math inline">⊖</span> task. Reported values
correspond to the average <span class="math inline">±</span> standard deviation
over the 5 runs. Best (lowest) results are in bold.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal_fig7_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig7/AS:1155814379270157@1652579030644/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filter <span class="math inline"><em>w</em></span>, corresponding
parameter <span class="math inline"><em>p</em>/<em>α</em></span>, RMSE between
the learned filter and the target structuring element, MSE training loss at
convergence and number of training epochs for <span class="math
inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span
class="math inline">ℒMorph</span> and <span class="math inline">𝒮Morph</span>
layers on a dilation <span class="math inline">⊕</span> task. Reported values
correspond to the average <span class="math inline">±</span> standard deviation
over the 5 runs. Best (lowest) results are in bold.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Network-architecture-used-for-the-opening-closing-scenarios-Blue-blocks-are-trainable_fig8_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig8/AS:1155814379257866@1652579030669/Network-architecture-used-for-the-opening-closing-scenarios-Blue-blocks-are-trainable.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Network architecture used for the opening/closing scenarios. Blue blocks are
trainable units. A scenario is defined as the choice of <span class="math
inline">∘</span> or <span class="math inline">•</span> and one of the 6 target
structuring elements in the upper path, and the choice of <span class="math
inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span
class="math inline">ℒMorph</span> or <span class="math inline">𝒮Morph</span> for
both consecutive layers in the lower path.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig9_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig9/AS:1155814379266063@1652579030697/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filters <span class="math
inline"><em>w</em><sub><em>i</em></sub></span>, corresponding parameter <span
class="math
inline"><em>p</em><sub><em>i</em></sub>/<em>α</em><sub><em>i</em></sub></span>
and RMSE<span class="math inline"><em></em><sub><em>i</em></sub></span> between
the learned filter and the target structuring element for both layers (<span
        class="math inline"><em>i</em> ∈ {1, 2}</span>), MSE training loss at
convergence and number of training epochs for <span class="math
inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span
class="math inline">ℒMorph</span> and <span class="math inline">𝒮Morph</span>
layers on an opening <span class="math inline">∘</span> task. Best (lowest)
results are in bold. Abnormal results are in red.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig10_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig10/AS:1155814379274251@1652579030724/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filters <span class="math
inline"><em>w</em><sub><em>i</em></sub></span>, corresponding parameter <span
class="math
inline"><em>p</em><sub><em>i</em></sub>/<em>α</em><sub><em>i</em></sub></span>
and RMSE<span class="math inline"><em></em><sub><em>i</em></sub></span> between
the learned filter and the target structuring element for both layers (<span
        class="math inline"><em>i</em> ∈ {1, 2}</span>), MSE training loss at
convergence and number of training epochs for <span class="math
inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span
class="math inline">ℒMorph</span> and <span class="math inline">𝒮Morph</span>
layers on a closing <span class="math inline">•</span> task. Best (lowest)
results are in bold. Abnormal results are in red.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Examples-of-network-divergent-behavior-for-PConv-cross7-documentclass12ptminimal_fig11_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig11/AS:1155814379261965@1652579030780/Examples-of-network-divergent-behavior-for-PConv-cross7-documentclass12ptminimal.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Examples of network divergent behavior for <span class="math
inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>/<em>cross7</em>/<span
class="math inline">•</span> and <span class="math
inline">ℒMorph</span>/<em>cross3</em>/<span class="math inline">•</span>
scenarios, with average parameter values at convergence.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Convergence-of-two-consecutive-SMorphdocumentclass12ptminimal-usepackageamsmath_fig12_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig12/AS:1155814379270169@1652579030811/Convergence-of-two-consecutive-SMorphdocumentclass12ptminimal-usepackageamsmath.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Convergence of two consecutive <span class="math inline">𝒮Morph</span> layers in
a closing <span class="math inline">•</span> scenario, with corresponding values
of <span class="math inline"><em>α</em><sub>1</sub></span> and <span class="math
inline"><em>α</em><sub>2</sub></span>. Target structuring elements are
<em>diamond3</em> (top row), <em>cross7</em> (middle row) and <em>disk2</em>
(bottom row). Layers are shown at initialization, <span class="math
inline">1%</span>, <span class="math inline">2%</span>, <span class="math
inline">3%</span>, <span class="math inline">5%</span>, <span class="math
inline">7%</span>, <span class="math inline">10%</span>, <span class="math
inline">20%</span>, <span class="math inline">50%</span> and <span class="math
inline">100%</span> of total number of training epochs.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filters-for-opening-documentclass12ptminimal-usepackageamsmath_fig13_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig13/AS:1155814379257876@1652579030842/Learned-filters-for-opening-documentclass12ptminimal-usepackageamsmath.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filters for opening <span class="math inline">∘</span> and closing <span
class="math inline">•</span> operations for <span class="math
inline">ℒMorph</span> and <span class="math inline">𝒮Morph</span> for
<em>cross3</em> and <em>disk2</em> in a <span class="math inline">5 × 5</span>
spatial support, as well as <em>disk3</em> in <span class="math
inline">9 × 9</span>, <span class="math inline">11 × 11</span> and <span
class="math inline">13 × 13</span> spatial supports.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig14_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig14/AS:1155814379266078@1652579030872/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
7<span class="math inline">×</span>7 target binary structuring elements. Yellow
(resp. blue) corresponds to boolean <span class="smallcaps">true</span> (resp.
        <span class="smallcaps">false</span>).
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filter-w-and-its-clipped-version-with-associated-color-bars-and-quantitative_fig15_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig15/AS:1155814379274262@1652579030956/Learned-filter-w-and-its-clipped-version-with-associated-color-bars-and-quantitative.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filter <span class="math inline"><em>w</em></span> and its clipped
version with associated colorbars, and quantitative metrics for a <span
class="math inline">𝒮Morph</span> layer for binary erosion <span class="math
inline">⊖</span> (first row) and binary dilation <span class="math
inline">⊕</span> (second row) scenarios.
</i>
</div><br /><br />

<a
href="https://www.researchgate.net/figure/Learned-filter-wi1-2documentclass12ptminimal-usepackageamsmath_fig16_360606987"><img
src="https://www.researchgate.net/publication/360606987/figure/fig16/AS:1155814379261988@1652579030998/Learned-filter-wi1-2documentclass12ptminimal-usepackageamsmath.png">
</a>

<div markdown="span" class="alert alert-primary" role="alert">
<i>
Learned filter <span class="math
inline"><em>w</em><sub><em>i</em> ∈ {1, 2}</sub></span> and its clipped version,
    and quantitative metrics for two <span class="math inline">𝒮Morph</span>
    layers for binary opening <span class="math inline">∘</span> (first row) and
    binary closing <span class="math inline">•</span> (second row) scenarios.
    Abnormal results are in red.
</i>
</div><br /><br />
